# VOKG - Video Object Knowledge Graph

A complete system that extracts objects from videos using SAM 2, tracks them across frames, detects interactions, builds a temporal knowledge graph, and generates AI-powered narratives explaining what happens in the video.

## ğŸ¯ Overview

VOKG transforms raw videos into structured, queryable knowledge graphs with:
- **Object Detection & Tracking**: SAM 2 segments every object and tracks them across frames
- **Interaction Detection**: Spatial and temporal heuristics detect proximity, containment, chasing, following, etc.
- **Knowledge Graph**: Neo4j graph with objects as nodes and interactions/temporal/causal relationships as edges
- **LLM Reasoning**: GPT-4 or Gemini generates natural language narratives explaining the video
- **Real-time Updates**: WebSocket notifications for processing progress
- **REST API**: Full-featured API for video upload, graph queries, and narrative retrieval

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚ (React + TypeScript)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      API Gateway (FastAPI)       â”‚
â”‚  - Auth (JWT)                    â”‚
â”‚  - Rate Limiting                 â”‚
â”‚  - WebSocket Progress            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Processing Pipeline            â”‚
â”‚  1. Video Ingestion                    â”‚
â”‚  2. Frame Extraction (FFmpeg)          â”‚
â”‚  3. SAM 2 Inference (GPU)              â”‚
â”‚  4. Interaction Detection (CPU)        â”‚
â”‚  5. Knowledge Graph Generation         â”‚
â”‚  6. LLM Reasoning (OpenAI/Gemini)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚  Neo4j   â”‚   Redis   â”‚
â”‚   (Metadata)    â”‚  (Graph) â”‚  (Cache)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3/MinIO       â”‚
â”‚  (Videos,       â”‚
â”‚   Frames,       â”‚
â”‚   Masks)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Docker & Docker Compose**
- **NVIDIA GPU** (for SAM 2 inference)
- **NVIDIA Container Toolkit**
- **OpenAI API Key** or **Google Gemini API Key**

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/vokg.git
cd vokg
```

### 2. Configure Environment

```bash
cp .env.example .env
```

Edit `.env` and set:
- `SECRET_KEY` (generate with `openssl rand -hex 32`)
- `ENCRYPTION_KEY` (generate with `openssl rand -hex 32`)
- `POSTGRES_PASSWORD`
- `NEO4J_PASSWORD`
- `OPENAI_API_KEY` (or `GEMINI_API_KEY`)

### 3. Download SAM 2 Model

```bash
mkdir -p models
cd models

# Download SAM 2 checkpoint (example for large model)
wget https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2_hiera_large.pt

# Download config
wget https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2_configs/sam2_hiera_l.yaml
```

### 4. Start Services

```bash
docker-compose up -d
```

This starts:
- PostgreSQL (port 5432)
- Neo4j (ports 7474, 7687)
- Redis (port 6379)
- MinIO (ports 9000, 9001)
- API Gateway (port 8000)
- Celery Workers (CPU, GPU, LLM, Graph)
- Flower (port 5555) - Celery monitoring

### 5. Run Database Migrations

```bash
docker-compose exec api alembic upgrade head
```

### 6. Create First User

```bash
curl -X POST http://localhost:8000/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "username": "testuser",
    "password": "SecurePass123"
  }'
```

### 7. Upload Video

```bash
# Login to get token
TOKEN=$(curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "SecurePass123"
  }' | jq -r '.access_token')

# Upload video
curl -X POST http://localhost:8000/api/v1/videos/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@video.mp4" \
  -F "title=My Test Video" \
  -F "description=Testing VOKG"
```

### 8. Monitor Progress

```bash
# WebSocket connection (use wscat or similar)
wscat -c "ws://localhost:8000/ws/{video_id}?token=$TOKEN"

# Or check Celery Flower
open http://localhost:5555
```

### 9. Query Knowledge Graph

```bash
# Get full graph
curl http://localhost:8000/api/v1/graphs/{video_id} \
  -H "Authorization: Bearer $TOKEN"

# Get narrative
curl http://localhost:8000/api/v1/graphs/{video_id}/narrative \
  -H "Authorization: Bearer $TOKEN"

# Natural language query
curl -X POST http://localhost:8000/api/v1/queries \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What objects are moving?",
    "video_id": 1
  }'
```

## ğŸ“ Project Structure

```
vokg-backend/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api_gateway/          # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py           # Entry point
â”‚   â”‚   â”œâ”€â”€ auth.py           # JWT authentication
â”‚   â”‚   â”œâ”€â”€ dependencies.py   # FastAPI dependencies
â”‚   â”‚   â”œâ”€â”€ middleware.py     # CORS, logging, errors
â”‚   â”‚   â”œâ”€â”€ websocket.py      # WebSocket manager
â”‚   â”‚   â””â”€â”€ routes/           # API endpoints
â”‚   â”‚       â”œâ”€â”€ videos.py     # Video management
â”‚   â”‚       â”œâ”€â”€ graphs.py     # Knowledge graph queries
â”‚   â”‚       â”œâ”€â”€ queries.py    # Natural language queries
â”‚   â”‚       â””â”€â”€ health.py     # Health checks
â”‚   â”œâ”€â”€ services/             # Celery workers
â”‚   â”‚   â”œâ”€â”€ video_ingestion/  # Video validation & queueing
â”‚   â”‚   â”œâ”€â”€ frame_extraction/ # FFmpeg frame extraction
â”‚   â”‚   â”œâ”€â”€ sam_inference/    # SAM 2 GPU inference
â”‚   â”‚   â”œâ”€â”€ interaction_detection/ # Interaction heuristics
â”‚   â”‚   â”œâ”€â”€ graph_generator/  # Neo4j graph building
â”‚   â”‚   â””â”€â”€ llm_reasoning/    # OpenAI/Gemini narrative generation
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py         # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ postgres.py       # PostgreSQL connection
â”‚   â”‚   â”œâ”€â”€ neo4j_client.py   # Neo4j client
â”‚   â”‚   â””â”€â”€ redis_client.py   # Redis client
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”‚   â”œâ”€â”€ logging.py        # Structured logging
â”‚   â”‚   â”œâ”€â”€ celery_app.py     # Celery configuration
â”‚   â”‚   â””â”€â”€ storage.py        # S3/MinIO client
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ video_utils.py    # Video processing utilities
â”‚       â”œâ”€â”€ encryption.py     # API key encryption
â”‚       â””â”€â”€ validators.py     # Input validation
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ api_gateway.Dockerfile
â”‚   â”œâ”€â”€ worker.Dockerfile
â”‚   â””â”€â”€ gpu_worker.Dockerfile
â”œâ”€â”€ alembic/                  # Database migrations
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-gpu.txt
â””â”€â”€ .env.example
```

## ğŸ”§ Configuration

All configuration is done via environment variables in `.env`:

### Critical Settings

- `SECRET_KEY`: JWT signing key (min 32 chars)
- `ENCRYPTION_KEY`: API key encryption (min 32 chars)
- `OPENAI_API_KEY` or `GEMINI_API_KEY`: LLM API key
- `POSTGRES_PASSWORD`: Database password
- `NEO4J_PASSWORD`: Graph database password

### Video Processing

- `FRAME_EXTRACTION_FPS`: Frames per second to extract (default: 1)
- `FRAME_EXTRACTION_MAX_FRAMES`: Maximum frames (default: 1000)
- `SAM_POINTS_PER_SIDE`: SAM grid density (default: 32)

### Interaction Detection

- `INTERACTION_PROXIMITY_THRESHOLD`: Distance for proximity (pixels)
- `INTERACTION_TEMPORAL_WINDOW`: Frames for temporal analysis
- `TRACKING_IOU_THRESHOLD`: IoU threshold for tracking

### LLM

- `LLM_PROVIDER`: `openai` or `gemini`
- `OPENAI_MODEL`: Model name (e.g., `gpt-4o`)
- `LLM_MAX_RETRIES`: Number of critique/revision passes

## ğŸ”Œ API Endpoints

### Authentication

- `POST /api/v1/auth/register` - Register new user
- `POST /api/v1/auth/login` - Login (returns JWT)
- `GET /api/v1/auth/me` - Get current user info

### Videos

- `POST /api/v1/videos/upload` - Upload video
- `GET /api/v1/videos` - List videos
- `GET /api/v1/videos/{id}` - Get video details
- `PATCH /api/v1/videos/{id}` - Update video metadata
- `DELETE /api/v1/videos/{id}` - Delete video
- `POST /api/v1/videos/{id}/reprocess` - Restart processing

### Knowledge Graphs

- `GET /api/v1/graphs/{video_id}` - Get full graph
- `GET /api/v1/graphs/{video_id}/objects` - Get objects
- `GET /api/v1/graphs/{video_id}/interactions` - Get interactions
- `GET /api/v1/graphs/{video_id}/narrative` - Get LLM narrative
- `GET /api/v1/graphs/{video_id}/metrics` - Get graph metrics
- `GET /api/v1/graphs/{video_id}/download` - Download graph (JSON/GEXF/GraphML)

### Queries

- `POST /api/v1/queries` - Natural language query
- `GET /api/v1/queries/{video_id}/suggestions` - Query suggestions

### Health

- `GET /health` - Basic health check
- `GET /health/detailed` - Check all services
- `GET /health/ready` - Kubernetes readiness
- `GET /health/live` - Kubernetes liveness

### WebSocket

- `WS /ws/{video_id}?token={jwt}` - Real-time progress updates

## ğŸ§ª Development

### Run Tests

```bash
docker-compose exec api pytest
```

### Access Database

```bash
# PostgreSQL
docker-compose exec postgres psql -U vokg -d vokg

# Neo4j Browser
open http://localhost:7474

# MinIO Console
open http://localhost:9001
```

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f worker-gpu
```

### Generate Database Migration

```bash
docker-compose exec api alembic revision --autogenerate -m "Description"
docker-compose exec api alembic upgrade head
```

## ğŸ› Troubleshooting

### GPU Not Detected

```bash
# Check NVIDIA runtime
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# If fails, install nvidia-container-toolkit
# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
```

### SAM 2 Model Not Found

Ensure models are in `./models/` directory and paths in `.env` are correct.

### Out of Memory

Reduce `SAM_BATCH_SIZE` or `SAM_POINTS_PER_SIDE` in `.env`.

### LLM API Errors

Check API key is valid and rate limits not exceeded.

## ğŸ“Š Monitoring

- **Celery Flower**: http://localhost:5555 - Task monitoring
- **Neo4j Browser**: http://localhost:7474 - Graph visualization
- **MinIO Console**: http://localhost:9001 - Storage management

## ğŸ” Security Notes

- **NEVER** commit `.env` file
- Rotate `SECRET_KEY` and `ENCRYPTION_KEY` regularly
- Use strong passwords for databases
- Enable HTTPS in production
- Restrict CORS origins to your frontend domain
- Store API keys encrypted in database (already implemented)

## ğŸ“ˆ Performance Tips

1. **GPU Memory**: Adjust `SAM_BATCH_SIZE` based on GPU VRAM
2. **Frame Extraction**: Lower `FRAME_EXTRACTION_FPS` for faster processing
3. **Worker Concurrency**: Tune Celery worker counts in `docker-compose.yml`
4. **Database Indexes**: Already optimized in models
5. **Caching**: Redis caching enabled for graph queries

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“ License

MIT License - See LICENSE file

## ğŸ™ Acknowledgments

- [SAM 2](https://github.com/facebookresearch/sam2) - Meta AI
- [FastAPI](https://fastapi.tiangolo.com/)
- [Neo4j](https://neo4j.com/)
- [Celery](https://docs.celeryq.dev/)

---

**Built with â¤ï¸ for video understanding**
#   V O K G  
 